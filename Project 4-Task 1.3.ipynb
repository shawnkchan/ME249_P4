{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "978eb101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.008, 550, 0.525, 306.7], [0.008, 650, 0.525, 298.5], [0.008, 750, 0.525, 294.2], [0.008, 850, 0.525, 290.2], [0.008, 950, 0.524, 286.9], [0.008, 1050, 0.524, 284.1], [0.008, 1150, 0.525, 281.7], [0.008, 850, 0.524, 290.31], [0.008, 550, 0.734, 307.9], [0.008, 750, 0.735, 295.5], [0.008, 950, 0.735, 287.8], [0.008, 1050, 0.735, 285.0], [0.008, 1150, 0.735, 282.5], [0.008, 850, 0.734, 291.3], [0.008, 550, 0.945, 308.6], [0.008, 750, 0.945, 296.2], [0.008, 950, 0.945, 288.5], [0.008, 1150, 0.945, 283.1], [0.008, 850, 0.945, 291.9], [0.011, 550, 0.525, 328.0], [0.011, 750, 0.525, 311.2], [0.011, 950, 0.525, 300.8], [0.011, 1150, 0.525, 293.6], [0.011, 850, 0.525, 305.5], [0.011, 550, 0.735, 329.6], [0.011, 750, 0.735, 312.6], [0.011, 950, 0.735, 302.0], [0.011, 1050, 0.735, 299.4], [0.011, 1150, 0.735, 294.8], [0.011, 850, 0.735, 306.8], [0.011, 550, 0.945, 330.7], [0.011, 750, 0.945, 313.6], [0.011, 950, 0.944, 302.9], [0.011, 1150, 0.945, 295.6], [0.011, 850, 0.944, 307.7], [0.011, 700, 0.734, 324.7], [0.013, 550, 0.525, 342.2], [0.013, 750, 0.524, 322.3], [0.013, 950, 0.524, 310.0], [0.013, 1150, 0.525, 301.6], [0.013, 850, 0.524, 315.5], [0.013, 550, 0.734, 344.1], [0.013, 750, 0.735, 324.0], [0.013, 950, 0.735, 311.5], [0.013, 1050, 0.735, 306.3], [0.013, 1150, 0.735, 302.9], [0.013, 850, 0.734, 317.1], [0.013, 550, 0.945, 345.3], [0.013, 750, 0.944, 325.1], [0.013, 950, 0.944, 312.5], [0.013, 1150, 0.945, 303.9], [0.013, 850, 0.945, 318.2]]\n",
      "[[8.0000e-03 5.5000e+02 5.2500e-01 3.0670e+02]\n",
      " [8.0000e-03 6.5000e+02 5.2500e-01 2.9850e+02]\n",
      " [8.0000e-03 7.5000e+02 5.2500e-01 2.9420e+02]\n",
      " [8.0000e-03 8.5000e+02 5.2500e-01 2.9020e+02]\n",
      " [8.0000e-03 9.5000e+02 5.2400e-01 2.8690e+02]\n",
      " [8.0000e-03 1.0500e+03 5.2400e-01 2.8410e+02]\n",
      " [8.0000e-03 1.1500e+03 5.2500e-01 2.8170e+02]\n",
      " [8.0000e-03 8.5000e+02 5.2400e-01 2.9031e+02]\n",
      " [8.0000e-03 5.5000e+02 7.3400e-01 3.0790e+02]\n",
      " [8.0000e-03 7.5000e+02 7.3500e-01 2.9550e+02]\n",
      " [8.0000e-03 9.5000e+02 7.3500e-01 2.8780e+02]\n",
      " [8.0000e-03 1.0500e+03 7.3500e-01 2.8500e+02]\n",
      " [8.0000e-03 1.1500e+03 7.3500e-01 2.8250e+02]\n",
      " [8.0000e-03 8.5000e+02 7.3400e-01 2.9130e+02]\n",
      " [8.0000e-03 5.5000e+02 9.4500e-01 3.0860e+02]\n",
      " [8.0000e-03 7.5000e+02 9.4500e-01 2.9620e+02]\n",
      " [8.0000e-03 9.5000e+02 9.4500e-01 2.8850e+02]\n",
      " [8.0000e-03 1.1500e+03 9.4500e-01 2.8310e+02]\n",
      " [8.0000e-03 8.5000e+02 9.4500e-01 2.9190e+02]\n",
      " [1.1000e-02 5.5000e+02 5.2500e-01 3.2800e+02]\n",
      " [1.1000e-02 7.5000e+02 5.2500e-01 3.1120e+02]\n",
      " [1.1000e-02 9.5000e+02 5.2500e-01 3.0080e+02]\n",
      " [1.1000e-02 1.1500e+03 5.2500e-01 2.9360e+02]\n",
      " [1.1000e-02 8.5000e+02 5.2500e-01 3.0550e+02]\n",
      " [1.1000e-02 5.5000e+02 7.3500e-01 3.2960e+02]\n",
      " [1.1000e-02 7.5000e+02 7.3500e-01 3.1260e+02]\n",
      " [1.1000e-02 9.5000e+02 7.3500e-01 3.0200e+02]\n",
      " [1.1000e-02 1.0500e+03 7.3500e-01 2.9940e+02]\n",
      " [1.1000e-02 1.1500e+03 7.3500e-01 2.9480e+02]\n",
      " [1.1000e-02 8.5000e+02 7.3500e-01 3.0680e+02]\n",
      " [1.1000e-02 5.5000e+02 9.4500e-01 3.3070e+02]\n",
      " [1.1000e-02 7.5000e+02 9.4500e-01 3.1360e+02]\n",
      " [1.1000e-02 9.5000e+02 9.4400e-01 3.0290e+02]\n",
      " [1.1000e-02 1.1500e+03 9.4500e-01 2.9560e+02]\n",
      " [1.1000e-02 8.5000e+02 9.4400e-01 3.0770e+02]\n",
      " [1.1000e-02 7.0000e+02 7.3400e-01 3.2470e+02]\n",
      " [1.3000e-02 5.5000e+02 5.2500e-01 3.4220e+02]\n",
      " [1.3000e-02 7.5000e+02 5.2400e-01 3.2230e+02]\n",
      " [1.3000e-02 9.5000e+02 5.2400e-01 3.1000e+02]\n",
      " [1.3000e-02 1.1500e+03 5.2500e-01 3.0160e+02]\n",
      " [1.3000e-02 8.5000e+02 5.2400e-01 3.1550e+02]\n",
      " [1.3000e-02 5.5000e+02 7.3400e-01 3.4410e+02]\n",
      " [1.3000e-02 7.5000e+02 7.3500e-01 3.2400e+02]\n",
      " [1.3000e-02 9.5000e+02 7.3500e-01 3.1150e+02]\n",
      " [1.3000e-02 1.0500e+03 7.3500e-01 3.0630e+02]\n",
      " [1.3000e-02 1.1500e+03 7.3500e-01 3.0290e+02]\n",
      " [1.3000e-02 8.5000e+02 7.3400e-01 3.1710e+02]\n",
      " [1.3000e-02 5.5000e+02 9.4500e-01 3.4530e+02]\n",
      " [1.3000e-02 7.5000e+02 9.4400e-01 3.2510e+02]\n",
      " [1.3000e-02 9.5000e+02 9.4400e-01 3.1250e+02]\n",
      " [1.3000e-02 1.1500e+03 9.4500e-01 3.0390e+02]\n",
      " [1.3000e-02 8.5000e+02 9.4500e-01 3.1820e+02]]\n",
      "[[0.06157], [0.07269], [0.08396], [0.09347], [0.10635], [0.11521], [0.1287], [0.09516], [0.04398], [0.05997], [0.07596], [0.08343], [0.0919], [0.06797], [0.0342], [0.04664], [0.05908], [0.0715], [0.05286], [0.0846], [0.1154], [0.1462], [0.177], [0.1308], [0.06047], [0.08246], [0.1044], [0.1134], [0.1264], [0.0934], [0.047], [0.06413], [0.08124], [0.09834], [0.072691], [0.087196], [0.10005], [0.13644], [0.17282], [0.2092], [0.15463], [0.07147], [0.09745], [0.12344], [0.13302], [0.1494], [0.11045], [0.05558], [0.0758], [0.09601], [0.1162], [0.0859]]\n",
      "[[0.06157 ]\n",
      " [0.07269 ]\n",
      " [0.08396 ]\n",
      " [0.09347 ]\n",
      " [0.10635 ]\n",
      " [0.11521 ]\n",
      " [0.1287  ]\n",
      " [0.09516 ]\n",
      " [0.04398 ]\n",
      " [0.05997 ]\n",
      " [0.07596 ]\n",
      " [0.08343 ]\n",
      " [0.0919  ]\n",
      " [0.06797 ]\n",
      " [0.0342  ]\n",
      " [0.04664 ]\n",
      " [0.05908 ]\n",
      " [0.0715  ]\n",
      " [0.05286 ]\n",
      " [0.0846  ]\n",
      " [0.1154  ]\n",
      " [0.1462  ]\n",
      " [0.177   ]\n",
      " [0.1308  ]\n",
      " [0.06047 ]\n",
      " [0.08246 ]\n",
      " [0.1044  ]\n",
      " [0.1134  ]\n",
      " [0.1264  ]\n",
      " [0.0934  ]\n",
      " [0.047   ]\n",
      " [0.06413 ]\n",
      " [0.08124 ]\n",
      " [0.09834 ]\n",
      " [0.072691]\n",
      " [0.087196]\n",
      " [0.10005 ]\n",
      " [0.13644 ]\n",
      " [0.17282 ]\n",
      " [0.2092  ]\n",
      " [0.15463 ]\n",
      " [0.07147 ]\n",
      " [0.09745 ]\n",
      " [0.12344 ]\n",
      " [0.13302 ]\n",
      " [0.1494  ]\n",
      " [0.11045 ]\n",
      " [0.05558 ]\n",
      " [0.0758  ]\n",
      " [0.09601 ]\n",
      " [0.1162  ]\n",
      " [0.0859  ]]\n",
      "13.0\n"
     ]
    }
   ],
   "source": [
    "'''>>>>> start CodeP4.1F23\n",
    "V.P. Carey ME249, Fall 2023\n",
    "Keras Neural Network Modeling '''\n",
    "#import useful packages\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import keras.backend as kb\n",
    "import tensorflow as tf\n",
    "#the following 2 lines are only needed for Mac OS machines\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "# define meadian values of input variables - add your values here\n",
    "\n",
    "import statistics\n",
    "import numpy\n",
    "xdata = []\n",
    "ydata = []\n",
    "#xdata.append([ Di(m), qoflux (kW/m^2), exit quality, max wall temperature (deg C)])\n",
    "xdata.append([0.008, 550, 0.525, 306.7])\n",
    "xdata.append([0.008, 650, 0.525, 298.5])\n",
    "xdata.append([0.008, 750, 0.525, 294.2])\n",
    "xdata.append([0.008, 850, 0.525, 290.2])\n",
    "xdata.append([0.008, 950, 0.524, 286.9])\n",
    "xdata.append([0.008, 1050, 0.524, 284.1])\n",
    "xdata.append([0.008, 1150, 0.525, 281.7])\n",
    "xdata.append([0.008, 850, 0.524, 290.31])\n",
    "xdata.append([0.008, 550, 0.734, 307.9])\n",
    "xdata.append([0.008, 750, 0.735, 295.5])\n",
    "xdata.append([0.008, 950, 0.735, 287.8])\n",
    "xdata.append([0.008, 1050, 0.735, 285.0])\n",
    "xdata.append([0.008, 1150, 0.735, 282.5])\n",
    "xdata.append([0.008, 850, 0.734, 291.3])\n",
    "xdata.append([0.008, 550, 0.945, 308.6])\n",
    "xdata.append([0.008, 750, 0.945, 296.2])\n",
    "xdata.append([0.008, 950, 0.945, 288.5])\n",
    "xdata.append([0.008, 1150, 0.945, 283.1])\n",
    "xdata.append([0.008, 850, 0.945, 291.9])\n",
    "xdata.append([0.011, 550, 0.525, 328.0])\n",
    "xdata.append([0.011, 750, 0.525, 311.2])\n",
    "xdata.append([0.011, 950, 0.525, 300.8])\n",
    "xdata.append([0.011, 1150, 0.525, 293.6])\n",
    "xdata.append([0.011, 850, 0.525, 305.5])\n",
    "xdata.append([0.011, 550, 0.735, 329.6])\n",
    "xdata.append([0.011, 750, 0.735, 312.6])\n",
    "xdata.append([0.011, 950, 0.735, 302.0])\n",
    "xdata.append([0.011, 1050, 0.735, 299.4])\n",
    "xdata.append([0.011, 1150, 0.735, 294.8])\n",
    "xdata.append([0.011, 850, 0.735, 306.8])\n",
    "xdata.append([0.011, 550, 0.945, 330.7])\n",
    "xdata.append([0.011, 750, 0.945, 313.6])\n",
    "xdata.append([0.011, 950, 0.944, 302.9])\n",
    "xdata.append([0.011, 1150, 0.945, 295.6])\n",
    "xdata.append([0.011, 850, 0.944, 307.7])\n",
    "xdata.append([0.011, 700, 0.734, 324.7])\n",
    "xdata.append([0.013, 550, 0.525, 342.2])\n",
    "xdata.append([0.013, 750, 0.524, 322.3])\n",
    "xdata.append([0.013, 950, 0.524, 310.0])\n",
    "xdata.append([0.013, 1150, 0.525, 301.6])\n",
    "xdata.append([0.013, 850, 0.524, 315.5])\n",
    "xdata.append([0.013, 550, 0.734, 344.1])\n",
    "xdata.append([0.013, 750, 0.735, 324.0])\n",
    "xdata.append([0.013, 950, 0.735, 311.5])\n",
    "xdata.append([0.013, 1050, 0.735, 306.3])\n",
    "xdata.append([0.013, 1150, 0.735, 302.9])\n",
    "xdata.append([0.013, 850, 0.734, 317.1])\n",
    "xdata.append([0.013, 550, 0.945, 345.3])\n",
    "xdata.append([0.013, 750, 0.944, 325.1])\n",
    "xdata.append([0.013, 950, 0.944, 312.5])\n",
    "xdata.append([0.013, 1150, 0.945, 303.9])\n",
    "xdata.append([0.013, 850, 0.945, 318.2])\n",
    "\n",
    "#data.append([mdot (kg/s)])\n",
    "ydata.append([0.06157])\n",
    "ydata.append([0.07269])\n",
    "ydata.append([0.08396])\n",
    "ydata.append([0.09347])\n",
    "ydata.append([0.10635])\n",
    "ydata.append([0.11521])\n",
    "ydata.append([0.1287])\n",
    "ydata.append([0.09516])\n",
    "ydata.append([0.04398])\n",
    "ydata.append([0.05997])\n",
    "ydata.append([0.07596])\n",
    "ydata.append([0.08343])\n",
    "ydata.append([0.0919])\n",
    "ydata.append([0.06797])\n",
    "ydata.append([0.0342])\n",
    "ydata.append([0.04664])\n",
    "ydata.append([0.05908])\n",
    "ydata.append([0.0715])\n",
    "ydata.append([0.05286])\n",
    "ydata.append([0.0846])\n",
    "ydata.append([0.1154])\n",
    "ydata.append([0.1462])\n",
    "ydata.append([0.177])\n",
    "ydata.append([0.1308])\n",
    "ydata.append([0.06047])\n",
    "ydata.append([0.08246])\n",
    "ydata.append([0.1044])\n",
    "ydata.append([0.1134])\n",
    "ydata.append([0.1264])\n",
    "ydata.append([0.0934])\n",
    "ydata.append([0.047])\n",
    "ydata.append([0.06413])\n",
    "ydata.append([0.08124])\n",
    "ydata.append([0.09834])\n",
    "ydata.append([0.072691])\n",
    "ydata.append([0.087196])\n",
    "ydata.append([0.10005])\n",
    "ydata.append([0.13644])\n",
    "ydata.append([0.17282])\n",
    "ydata.append([0.2092])\n",
    "ydata.append([0.15463])\n",
    "ydata.append([0.07147])\n",
    "ydata.append([0.09745])\n",
    "ydata.append([0.12344])\n",
    "ydata.append([0.13302])\n",
    "ydata.append([0.1494])\n",
    "ydata.append([0.11045])\n",
    "ydata.append([0.05558])\n",
    "ydata.append([0.0758])\n",
    "ydata.append([0.09601])\n",
    "ydata.append([0.1162])\n",
    "ydata.append([0.0859])\n",
    "xarray= numpy.array(xdata)\n",
    "yarray= numpy.array(ydata)\n",
    "print (xdata)\n",
    "print (xarray)\n",
    "print (ydata)\n",
    "print (yarray)\n",
    "\n",
    "#convert to:\n",
    "# median values of output variables\n",
    "ND=len(xarray)\n",
    "Diall = [row[0] for row in xdata]\n",
    "Dimed=statistics.median(Diall)\n",
    "q0all = [row[1] for row in xdata]\n",
    "q0med=statistics.median(q0all)\n",
    "xeall = [row[2] for row in xdata]\n",
    "xemed=statistics.median(xeall)\n",
    "Twall = [row[3] for row in xdata]\n",
    "Twmed=statistics.median(Twall)\n",
    "\n",
    "mall = [row[0] for row in ydata]\n",
    "mmed=statistics.median(mall)\n",
    "\n",
    "xdata = []\n",
    "ydata = []\n",
    "for i in range(ND):\n",
    "    xdata.append([xarray[i,0]/Dimed,xarray[i,1]/q0med,xarray[i,2]/xemed,xarray[i,3]/Twmed])\n",
    "    ydata.append([yarray[i,0]/mmed])\n",
    "\n",
    "xarray= np.array(xdata)\n",
    "yarray= np.array(ydata)\n",
    "\n",
    "#print (yarray)\n",
    "\n",
    "data_inputs = np.array(xdata)\n",
    "data_outputs = np.array(ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "379a75b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.64705882 1.28571429 1.08532983]\n",
      " [1.         0.64705882 1.         1.08171972]\n",
      " [1.18181818 1.11764706 0.71292517 1.01739416]\n",
      " [0.72727273 1.23529412 1.         0.93534624]\n",
      " [1.18181818 1.11764706 1.28435374 1.02559895]\n",
      " [0.72727273 0.88235294 1.         0.96980637]\n",
      " [0.72727273 0.88235294 1.28571429 0.97210371]\n",
      " [1.         1.35294118 1.28571429 0.97013456]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training_input,validation_input,training_output,validation_output = train_test_split(xarray,\n",
    "yarray, test_size=0.25, random_state=13)\n",
    "# print to check the shape of training and validation set\n",
    "training_input= np.array(training_input)#[:,[1,2,3]])\n",
    "training_output= np.array(training_output)\n",
    "validation_input= np.array(validation_input)#[:,[1,2,3]])\n",
    "validation_output= np.array(validation_output)\n",
    "\n",
    "print(validation_input)\n",
    "\n",
    "xarray=training_input\n",
    "yarray=training_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "60e227b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network model\n",
    "#As seen below, we have created four dense layers.\n",
    "#A dense layer is a layer in neural network that’s fully connected.\n",
    "#In other words, all the neurons in one layer are connected to all other neurons in the next layer.\n",
    "#In the first layer, we need to provide the input shape, which is 1 in our case.\n",
    "#The activation function we have chosen is elu, which stands for exponential linear unit. .\n",
    "from keras import backend as K\n",
    "#initialize weights with values between -0.2 and 0.5\n",
    "initializer = keras.initializers.RandomUniform(minval= -0.2, maxval=0.5)\n",
    "model = keras.Sequential([\n",
    "keras.layers.Dense(6, activation=K.elu, input_shape=[4], kernel_initializer=initializer),\n",
    "keras.layers.Dense(8, activation=K.elu, kernel_initializer=initializer),\n",
    "keras.layers.Dense(12, activation=K.elu, kernel_initializer=initializer),\n",
    "keras.layers.Dense(16, activation=K.elu, kernel_initializer=initializer),\n",
    "keras.layers.Dense(8, activation=K.elu, kernel_initializer=initializer),\n",
    "keras.layers.Dense(2, kernel_initializer=initializer)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "357a03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’re using RMSprop as our optimizer here. RMSprop stands for Root Mean Square Propagation.\n",
    "#It’s one of the most popular gradient descent optimization algorithms for deep learning networks.\n",
    "#RMSprop is an optimizer that’s reliable and fast.\n",
    "#We’re compiling the mode using the model.compile function. The loss function used here\n",
    "#is mean squared error. After the compilation of the model, we’ll use the fit method with ~500 epochs.\n",
    "#Number of epochs can be varied.\n",
    "#from tf.keras import optimizers\n",
    "rms = keras.optimizers.RMSprop(0.01)\n",
    "model.compile(loss='mean_absolute_error',optimizer=rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "07a87d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0695\n",
      "Epoch 2/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1294\n",
      "Epoch 3/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1232\n",
      "Epoch 4/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0612\n",
      "Epoch 5/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0748\n",
      "Epoch 6/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1230\n",
      "Epoch 7/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1191\n",
      "Epoch 8/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0651\n",
      "Epoch 9/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0831\n",
      "Epoch 10/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1253\n",
      "Epoch 11/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1124\n",
      "Epoch 12/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0692\n",
      "Epoch 13/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0781\n",
      "Epoch 14/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1346\n",
      "Epoch 15/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1202\n",
      "Epoch 16/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0664\n",
      "Epoch 17/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0637\n",
      "Epoch 18/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1315\n",
      "Epoch 19/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1204\n",
      "Epoch 20/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0627\n",
      "Epoch 21/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0782\n",
      "Epoch 22/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1228\n",
      "Epoch 23/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1205\n",
      "Epoch 24/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0653\n",
      "Epoch 25/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0742\n",
      "Epoch 26/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1194\n",
      "Epoch 27/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1173\n",
      "Epoch 28/800\n",
      "1/1 [==============================] - 0s 757us/step - loss: 0.0639\n",
      "Epoch 29/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0816\n",
      "Epoch 30/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1239\n",
      "Epoch 31/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1241\n",
      "Epoch 32/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0590\n",
      "Epoch 33/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0555\n",
      "Epoch 34/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1353\n",
      "Epoch 35/800\n",
      "1/1 [==============================] - 0s 654us/step - loss: 0.1298\n",
      "Epoch 36/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0631\n",
      "Epoch 37/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0709\n",
      "Epoch 38/800\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1420\n",
      "Epoch 39/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1206\n",
      "Epoch 40/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0598\n",
      "Epoch 41/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0857\n",
      "Epoch 42/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1130\n",
      "Epoch 43/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1141\n",
      "Epoch 44/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0641\n",
      "Epoch 45/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0786\n",
      "Epoch 46/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1250\n",
      "Epoch 47/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1148\n",
      "Epoch 48/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0636\n",
      "Epoch 49/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0797\n",
      "Epoch 50/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1217\n",
      "Epoch 51/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1089\n",
      "Epoch 52/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0681\n",
      "Epoch 53/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0737\n",
      "Epoch 54/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1199\n",
      "Epoch 55/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1165\n",
      "Epoch 56/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "Epoch 57/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0817\n",
      "Epoch 58/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1271\n",
      "Epoch 59/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1173\n",
      "Epoch 60/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0644\n",
      "Epoch 61/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0759\n",
      "Epoch 62/800\n",
      "1/1 [==============================] - 0s 817us/step - loss: 0.1224\n",
      "Epoch 63/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1121\n",
      "Epoch 64/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0642\n",
      "Epoch 65/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0763\n",
      "Epoch 66/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1301\n",
      "Epoch 67/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1128\n",
      "Epoch 68/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0650\n",
      "Epoch 69/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0668\n",
      "Epoch 70/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1310\n",
      "Epoch 71/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1138\n",
      "Epoch 72/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0623\n",
      "Epoch 73/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0719\n",
      "Epoch 74/800\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1131\n",
      "Epoch 75/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1153\n",
      "Epoch 76/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0666\n",
      "Epoch 77/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0688\n",
      "Epoch 78/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1278\n",
      "Epoch 79/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1116\n",
      "Epoch 80/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0666\n",
      "Epoch 81/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0759\n",
      "Epoch 82/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1310\n",
      "Epoch 83/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1190\n",
      "Epoch 84/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0597\n",
      "Epoch 85/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0733\n",
      "Epoch 86/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1262\n",
      "Epoch 87/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1121\n",
      "Epoch 88/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0641\n",
      "Epoch 89/800\n",
      "1/1 [==============================] - 0s 578us/step - loss: 0.0756\n",
      "Epoch 90/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1325\n",
      "Epoch 91/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1183\n",
      "Epoch 92/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0593\n",
      "Epoch 93/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0716\n",
      "Epoch 94/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1202\n",
      "Epoch 95/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1136\n",
      "Epoch 96/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0617\n",
      "Epoch 97/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0772\n",
      "Epoch 98/800\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1297\n",
      "Epoch 99/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 100/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0690\n",
      "Epoch 101/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0804\n",
      "Epoch 102/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1221\n",
      "Epoch 103/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1091\n",
      "Epoch 104/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0595\n",
      "Epoch 105/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0777\n",
      "Epoch 106/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1331\n",
      "Epoch 107/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1155\n",
      "Epoch 108/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0572\n",
      "Epoch 109/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0647\n",
      "Epoch 110/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1036\n",
      "Epoch 111/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1219\n",
      "Epoch 112/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0574\n",
      "Epoch 113/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0632\n",
      "Epoch 114/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1085\n",
      "Epoch 115/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1224\n",
      "Epoch 116/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0566\n",
      "Epoch 117/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0622\n",
      "Epoch 118/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1159\n",
      "Epoch 119/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1230\n",
      "Epoch 120/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0581\n",
      "Epoch 121/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0734\n",
      "Epoch 122/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1251\n",
      "Epoch 123/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1171\n",
      "Epoch 124/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0607\n",
      "Epoch 125/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0801\n",
      "Epoch 126/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1269\n",
      "Epoch 127/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1093\n",
      "Epoch 128/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0613\n",
      "Epoch 129/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0773\n",
      "Epoch 130/800\n",
      "1/1 [==============================] - 0s 990us/step - loss: 0.1367\n",
      "Epoch 131/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1162\n",
      "Epoch 132/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0557\n",
      "Epoch 133/800\n",
      "1/1 [==============================] - 0s 513us/step - loss: 0.0850\n",
      "Epoch 134/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1196\n",
      "Epoch 135/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1088\n",
      "Epoch 136/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0583\n",
      "Epoch 137/800\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.0760\n",
      "Epoch 138/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1319\n",
      "Epoch 139/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1180\n",
      "Epoch 140/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 141/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0641\n",
      "Epoch 142/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1151\n",
      "Epoch 143/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1141\n",
      "Epoch 144/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0584\n",
      "Epoch 145/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0710\n",
      "Epoch 146/800\n",
      "1/1 [==============================] - 0s 720us/step - loss: 0.1147\n",
      "Epoch 147/800\n",
      "1/1 [==============================] - 0s 993us/step - loss: 0.1143\n",
      "Epoch 148/800\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.0592\n",
      "Epoch 149/800\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.0657\n",
      "Epoch 150/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1150\n",
      "Epoch 151/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1158\n",
      "Epoch 152/800\n",
      "1/1 [==============================] - 0s 616us/step - loss: 0.0605\n",
      "Epoch 153/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0728\n",
      "Epoch 154/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1133\n",
      "Epoch 155/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1165\n",
      "Epoch 156/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0583\n",
      "Epoch 157/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0800\n",
      "Epoch 158/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1246\n",
      "Epoch 159/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1148\n",
      "Epoch 160/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0597\n",
      "Epoch 161/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0784\n",
      "Epoch 162/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1217\n",
      "Epoch 163/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1076\n",
      "Epoch 164/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0625\n",
      "Epoch 165/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0712\n",
      "Epoch 166/800\n",
      "1/1 [==============================] - 0s 988us/step - loss: 0.1012\n",
      "Epoch 167/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1202\n",
      "Epoch 168/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0581\n",
      "Epoch 169/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0687\n",
      "Epoch 170/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1320\n",
      "Epoch 171/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1204\n",
      "Epoch 172/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0549\n",
      "Epoch 173/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0587\n",
      "Epoch 174/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1118\n",
      "Epoch 175/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1258\n",
      "Epoch 176/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0569\n",
      "Epoch 177/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0558\n",
      "Epoch 178/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0876\n",
      "Epoch 179/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1111\n",
      "Epoch 180/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0505\n",
      "Epoch 181/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0926\n",
      "Epoch 182/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1218\n",
      "Epoch 183/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1256\n",
      "Epoch 184/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0521\n",
      "Epoch 185/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0498\n",
      "Epoch 186/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0695\n",
      "Epoch 187/800\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.1322\n",
      "Epoch 188/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0532\n",
      "Epoch 189/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0554\n",
      "Epoch 190/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1203\n",
      "Epoch 191/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1391\n",
      "Epoch 192/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0506\n",
      "Epoch 193/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0504\n",
      "Epoch 194/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1066\n",
      "Epoch 195/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1343\n",
      "Epoch 196/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0554\n",
      "Epoch 197/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0507\n",
      "Epoch 198/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1051\n",
      "Epoch 199/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1359\n",
      "Epoch 200/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0539\n",
      "Epoch 201/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0434\n",
      "Epoch 202/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0522\n",
      "Epoch 203/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1160\n",
      "Epoch 204/800\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0783\n",
      "Epoch 205/800\n",
      "1/1 [==============================] - 0s 431us/step - loss: 0.1209\n",
      "Epoch 206/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0804\n",
      "Epoch 207/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1195\n",
      "Epoch 208/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0507\n",
      "Epoch 209/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0952\n",
      "Epoch 210/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1201\n",
      "Epoch 211/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1360\n",
      "Epoch 212/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0508\n",
      "Epoch 213/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0413\n",
      "Epoch 214/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0493\n",
      "Epoch 215/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0983\n",
      "Epoch 216/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0856\n",
      "Epoch 217/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1358\n",
      "Epoch 218/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0537\n",
      "Epoch 219/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0544\n",
      "Epoch 220/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1288\n",
      "Epoch 221/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1400\n",
      "Epoch 222/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0534\n",
      "Epoch 223/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0451\n",
      "Epoch 224/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0583\n",
      "Epoch 225/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1362\n",
      "Epoch 226/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0564\n",
      "Epoch 227/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0536\n",
      "Epoch 228/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1314\n",
      "Epoch 229/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1407\n",
      "Epoch 230/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0505\n",
      "Epoch 231/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0432\n",
      "Epoch 232/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0554\n",
      "Epoch 233/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1295\n",
      "Epoch 234/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0591\n",
      "Epoch 235/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1200\n",
      "Epoch 236/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0786\n",
      "Epoch 237/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1280\n",
      "Epoch 238/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0567\n",
      "Epoch 239/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0890\n",
      "Epoch 240/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1247\n",
      "Epoch 241/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1311\n",
      "Epoch 242/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 243/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0462\n",
      "Epoch 244/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0867\n",
      "Epoch 245/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1355\n",
      "Epoch 246/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0539\n",
      "Epoch 247/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0417\n",
      "Epoch 248/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0435\n",
      "Epoch 249/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0954\n",
      "Epoch 250/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1098\n",
      "Epoch 251/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1466\n",
      "Epoch 252/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0545\n",
      "Epoch 253/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0456\n",
      "Epoch 254/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0559\n",
      "Epoch 255/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1158\n",
      "Epoch 256/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0819\n",
      "Epoch 257/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1384\n",
      "Epoch 258/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0549\n",
      "Epoch 259/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0433\n",
      "Epoch 260/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0913\n",
      "Epoch 261/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0774\n",
      "Epoch 262/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1447\n",
      "Epoch 263/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0520\n",
      "Epoch 264/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0548\n",
      "Epoch 265/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1721\n",
      "Epoch 266/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1255\n",
      "Epoch 267/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0544\n",
      "Epoch 268/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0679\n",
      "Epoch 269/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1436\n",
      "Epoch 270/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1256\n",
      "Epoch 271/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0467\n",
      "Epoch 272/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0537\n",
      "Epoch 273/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1221\n",
      "Epoch 274/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1248\n",
      "Epoch 275/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0479\n",
      "Epoch 276/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0546\n",
      "Epoch 277/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1067\n",
      "Epoch 278/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1213\n",
      "Epoch 279/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0497\n",
      "Epoch 280/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0833\n",
      "Epoch 281/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1196\n",
      "Epoch 282/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1226\n",
      "Epoch 283/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0494\n",
      "Epoch 284/800\n",
      "1/1 [==============================] - 0s 995us/step - loss: 0.0565\n",
      "Epoch 285/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1295\n",
      "Epoch 286/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1174\n",
      "Epoch 287/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0524\n",
      "Epoch 288/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0812\n",
      "Epoch 289/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1150\n",
      "Epoch 290/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1083\n",
      "Epoch 291/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0556\n",
      "Epoch 292/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0781\n",
      "Epoch 293/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1255\n",
      "Epoch 294/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1066\n",
      "Epoch 295/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0509\n",
      "Epoch 296/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0894\n",
      "Epoch 297/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0932\n",
      "Epoch 298/800\n",
      "1/1 [==============================] - 0s 765us/step - loss: 0.1135\n",
      "Epoch 299/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0497\n",
      "Epoch 300/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0545\n",
      "Epoch 301/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0705\n",
      "Epoch 302/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1259\n",
      "Epoch 303/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0482\n",
      "Epoch 304/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0435\n",
      "Epoch 305/800\n",
      "1/1 [==============================] - 0s 759us/step - loss: 0.0691\n",
      "Epoch 306/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0887\n",
      "Epoch 307/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1343\n",
      "Epoch 308/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0500\n",
      "Epoch 309/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0439\n",
      "Epoch 310/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0675\n",
      "Epoch 311/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1418\n",
      "Epoch 312/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0498\n",
      "Epoch 313/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 314/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0857\n",
      "Epoch 315/800\n",
      "1/1 [==============================] - 0s 139us/step - loss: 0.1028\n",
      "Epoch 316/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1428\n",
      "Epoch 317/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0572\n",
      "Epoch 318/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0604\n",
      "Epoch 319/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1696\n",
      "Epoch 320/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1208\n",
      "Epoch 321/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 322/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0640\n",
      "Epoch 323/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1233\n",
      "Epoch 324/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1273\n",
      "Epoch 325/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0444\n",
      "Epoch 326/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0450\n",
      "Epoch 327/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0642\n",
      "Epoch 328/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1341\n",
      "Epoch 329/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0502\n",
      "Epoch 330/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0401\n",
      "Epoch 331/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0408\n",
      "Epoch 332/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0440\n",
      "Epoch 333/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0735\n",
      "Epoch 334/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1318\n",
      "Epoch 335/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1379\n",
      "Epoch 336/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0636\n",
      "Epoch 337/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0516\n",
      "Epoch 338/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1282\n",
      "Epoch 339/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1373\n",
      "Epoch 340/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0491\n",
      "Epoch 341/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0405\n",
      "Epoch 342/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0496\n",
      "Epoch 343/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0940\n",
      "Epoch 344/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1483\n",
      "Epoch 345/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0466\n",
      "Epoch 346/800\n",
      "1/1 [==============================] - 0s 804us/step - loss: 0.0437\n",
      "Epoch 347/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0958\n",
      "Epoch 348/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0768\n",
      "Epoch 349/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1421\n",
      "Epoch 350/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0492\n",
      "Epoch 351/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0520\n",
      "Epoch 352/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1245\n",
      "Epoch 353/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1370\n",
      "Epoch 354/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0475\n",
      "Epoch 355/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0430\n",
      "Epoch 356/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0790\n",
      "Epoch 357/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0981\n",
      "Epoch 358/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1353\n",
      "Epoch 359/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0537\n",
      "Epoch 360/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0427\n",
      "Epoch 361/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "Epoch 362/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1479\n",
      "Epoch 363/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0496\n",
      "Epoch 364/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0398\n",
      "Epoch 365/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0439\n",
      "Epoch 366/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0431\n",
      "Epoch 367/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0726\n",
      "Epoch 368/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1392\n",
      "Epoch 369/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1329\n",
      "Epoch 370/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0621\n",
      "Epoch 371/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0735\n",
      "Epoch 372/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1444\n",
      "Epoch 373/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1286\n",
      "Epoch 374/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0499\n",
      "Epoch 375/800\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0468\n",
      "Epoch 376/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0786\n",
      "Epoch 377/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1371\n",
      "Epoch 378/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0491\n",
      "Epoch 379/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0389\n",
      "Epoch 380/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0399\n",
      "Epoch 381/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0442\n",
      "Epoch 382/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1078\n",
      "Epoch 383/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0793\n",
      "Epoch 384/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1347\n",
      "Epoch 385/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0678\n",
      "Epoch 386/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1070\n",
      "Epoch 387/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0842\n",
      "Epoch 388/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1357\n",
      "Epoch 389/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0517\n",
      "Epoch 390/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0401\n",
      "Epoch 391/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0443\n",
      "Epoch 392/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1275\n",
      "Epoch 393/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0612\n",
      "Epoch 394/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1056\n",
      "Epoch 395/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0920\n",
      "Epoch 396/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1300\n",
      "Epoch 397/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 398/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0466\n",
      "Epoch 399/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0654\n",
      "Epoch 400/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1474\n",
      "Epoch 401/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0497\n",
      "Epoch 402/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0519\n",
      "Epoch 403/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1118\n",
      "Epoch 404/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0595\n",
      "Epoch 405/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1126\n",
      "Epoch 406/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0780\n",
      "Epoch 407/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1353\n",
      "Epoch 408/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0511\n",
      "Epoch 409/800\n",
      "1/1 [==============================] - 0s 959us/step - loss: 0.0487\n",
      "Epoch 410/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0721\n",
      "Epoch 411/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1414\n",
      "Epoch 412/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0452\n",
      "Epoch 413/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0460\n",
      "Epoch 414/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0660\n",
      "Epoch 415/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1216\n",
      "Epoch 416/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1290\n",
      "Epoch 417/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0621\n",
      "Epoch 418/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0530\n",
      "Epoch 419/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1467\n",
      "Epoch 420/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1209\n",
      "Epoch 421/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0493\n",
      "Epoch 422/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0912\n",
      "Epoch 423/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0955\n",
      "Epoch 424/800\n",
      "1/1 [==============================] - 0s 510us/step - loss: 0.1222\n",
      "Epoch 425/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0444\n",
      "Epoch 426/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 427/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0930\n",
      "Epoch 428/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1214\n",
      "Epoch 429/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0464\n",
      "Epoch 430/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0476\n",
      "Epoch 431/800\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.0964\n",
      "Epoch 432/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1310\n",
      "Epoch 433/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0486\n",
      "Epoch 434/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0489\n",
      "Epoch 435/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0814\n",
      "Epoch 436/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1300\n",
      "Epoch 437/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0467\n",
      "Epoch 438/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0464\n",
      "Epoch 439/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0585\n",
      "Epoch 440/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1297\n",
      "Epoch 441/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0471\n",
      "Epoch 442/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0663\n",
      "Epoch 443/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1522\n",
      "Epoch 444/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1217\n",
      "Epoch 445/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0604\n",
      "Epoch 446/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0867\n",
      "Epoch 447/800\n",
      "1/1 [==============================] - 0s 507us/step - loss: 0.1206\n",
      "Epoch 448/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1160\n",
      "Epoch 449/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0441\n",
      "Epoch 450/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0797\n",
      "Epoch 451/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0964\n",
      "Epoch 452/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1168\n",
      "Epoch 453/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0435\n",
      "Epoch 454/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 455/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0924\n",
      "Epoch 456/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1191\n",
      "Epoch 457/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0446\n",
      "Epoch 458/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0569\n",
      "Epoch 459/800\n",
      "1/1 [==============================] - 0s 684us/step - loss: 0.1403\n",
      "Epoch 460/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1104\n",
      "Epoch 461/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0483\n",
      "Epoch 462/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0662\n",
      "Epoch 463/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1148\n",
      "Epoch 464/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1142\n",
      "Epoch 465/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0491\n",
      "Epoch 466/800\n",
      "1/1 [==============================] - 0s 911us/step - loss: 0.0624\n",
      "Epoch 467/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1149\n",
      "Epoch 468/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1126\n",
      "Epoch 469/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0475\n",
      "Epoch 470/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0604\n",
      "Epoch 471/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1191\n",
      "Epoch 472/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1078\n",
      "Epoch 473/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0490\n",
      "Epoch 474/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0581\n",
      "Epoch 475/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1148\n",
      "Epoch 476/800\n",
      "1/1 [==============================] - 0s 973us/step - loss: 0.1099\n",
      "Epoch 477/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0450\n",
      "Epoch 478/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "Epoch 479/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0791\n",
      "Epoch 480/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1110\n",
      "Epoch 481/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0472\n",
      "Epoch 482/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0610\n",
      "Epoch 483/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 484/800\n",
      "1/1 [==============================] - 0s 508us/step - loss: 0.1109\n",
      "Epoch 485/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0541\n",
      "Epoch 486/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0978\n",
      "Epoch 487/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0425\n",
      "Epoch 488/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0496\n",
      "Epoch 489/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0410\n",
      "Epoch 490/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 491/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0469\n",
      "Epoch 492/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0767\n",
      "Epoch 493/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1388\n",
      "Epoch 494/800\n",
      "1/1 [==============================] - 0s 886us/step - loss: 0.1178\n",
      "Epoch 495/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0444\n",
      "Epoch 496/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0587\n",
      "Epoch 497/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1277\n",
      "Epoch 498/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1163\n",
      "Epoch 499/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0537\n",
      "Epoch 500/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0920\n",
      "Epoch 501/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0572\n",
      "Epoch 502/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1027\n",
      "Epoch 503/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0563\n",
      "Epoch 504/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1018\n",
      "Epoch 505/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0610\n",
      "Epoch 506/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1051\n",
      "Epoch 507/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0528\n",
      "Epoch 508/800\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1143\n",
      "Epoch 509/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0458\n",
      "Epoch 510/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0684\n",
      "Epoch 511/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1169\n",
      "Epoch 512/800\n",
      "1/1 [==============================] - 0s 882us/step - loss: 0.1173\n",
      "Epoch 513/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0499\n",
      "Epoch 514/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0572\n",
      "Epoch 515/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1048\n",
      "Epoch 516/800\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1227\n",
      "Epoch 517/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0428\n",
      "Epoch 518/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0474\n",
      "Epoch 519/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0798\n",
      "Epoch 520/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1236\n",
      "Epoch 521/800\n",
      "1/1 [==============================] - 0s 506us/step - loss: 0.0450\n",
      "Epoch 522/800\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0498\n",
      "Epoch 523/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0517\n",
      "Epoch 524/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0902\n",
      "Epoch 525/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1243\n",
      "Epoch 526/800\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0463\n",
      "Epoch 527/800\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0628\n",
      "Epoch 528/800\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1056\n",
      "Epoch 529/800\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1198Restoring model weights from the end of the best epoch.\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1198\n",
      "Epoch 00529: early stopping\n",
      "best epoch =  379\n",
      "smallest loss = 0.038933463394641876\n",
      "INFO:tensorflow:Assets written to: ./best_model\\assets\n"
     ]
    }
   ],
   "source": [
    "#After the compilation of the model, we’ll use the fit method with 500 epochs.\n",
    "#I started with epochs value of 100 and then tested the model after training.\n",
    "#The prediction was not that good. Then I modified the number of epochs to 200 and tested the model again.\n",
    "#Accuracy had improved slightly, but figured I’d give it one more try. Finally, at 500 epochs\n",
    "#I found acceptable prediction accuracy.\n",
    "#The fit method takes three parameters; namely, x, y, and number of epochs.\n",
    "#During model training, if all the batches of data are seen by the model once,\n",
    "#we say that one epoch has been completed.\n",
    "# Add an early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "monitor='loss',\n",
    "mode='min',\n",
    "patience = 90,\n",
    "restore_best_weights = True,\n",
    "verbose=1)\n",
    "# Add a checkpoint where loss is minimum, and save that model\n",
    "mc = keras.callbacks.ModelCheckpoint('best_model.SB', monitor='loss',\n",
    "mode='min', verbose=1, save_best_only=True)\n",
    "historyData = model.fit(xarray,yarray,epochs=800,callbacks=[es])\n",
    "loss_hist = historyData.history['loss']\n",
    "#The above line will return a dictionary, access it's info like this:\n",
    "best_epoch = np.argmin(historyData.history['loss']) + 1\n",
    "print ('best epoch = ', best_epoch)\n",
    "print('smallest loss =', np.min(loss_hist))\n",
    "model.save('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e782636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code can be used to reconstruct the saved model.\n",
    "recon_model = keras.models.load_model(\"best_model\")\n",
    "# the name of the model is now \"recon_model\". You can then use this model to do predictions for comparisons.\n",
    "# See the previous project for code to do the comparisons.\n",
    "# NOTE: If you get an error message when trying to run with the line\n",
    "# recon_model = tf.keras.models.load_model(\"best_model\")\n",
    "# try running prediction calculations with model.predict() (as in the code for project 2)\n",
    "# with the line recon_model = tf.keras.models.load_model(\"best_model\") removed.\n",
    "# That may avoid the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb462f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
